{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c1a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/abhishek/anaconda3/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: tavily-python in /Users/abhishek/anaconda3/lib/python3.11/site-packages (0.7.8)\n",
      "Requirement already satisfied: requests in /Users/abhishek/anaconda3/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: langchain in /Users/abhishek/anaconda3/lib/python3.11/site-packages (0.3.26)\n",
      "Requirement already satisfied: faiss-cpu in /Users/abhishek/anaconda3/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: sentence-transformers in /Users/abhishek/anaconda3/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from tavily-python) (0.9.0)\n",
      "Requirement already satisfied: httpx in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.66)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.55.4)\n",
      "Requirement already satisfied: tqdm in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: filelock in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from httpx->tavily-python) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: sympy in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/abhishek/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv tavily-python requests langchain faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3076bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/l_bc5j753tx9_bp8mg05l0x00000gn/T/ipykernel_51645/4166252925.py:37: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from tavily import TavilyClient\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# LangChain components for RAG\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# --- Load API Keys & Configure Clients (same as before) ---\n",
    "load_dotenv()\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "OPENROUTER_HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"https://github.com/guy-hartstein/company-research-agent\",\n",
    "    \"X-Title\": \"Wavess GTM Intelligence Prototype\",\n",
    "}\n",
    "\n",
    "# --- Define LLMs & Embedding Model ---\n",
    "LLM_MODELS = [\n",
    "    \"google/gemini-2.0-flash-exp:free\",\n",
    "    \"kwaipilot/kat-coder-pro:free\",\n",
    "    \"openrouter/polaris-alpha\",\n",
    "]\n",
    "\n",
    "# Use a powerful, free, and local embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45107361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openrouter_with_retry(prompt):\n",
    "    \"\"\"\n",
    "    Sends a prompt to OpenRouter, trying a list of models in sequence.\n",
    "    \"\"\"\n",
    "    for model in LLM_MODELS:\n",
    "        try:\n",
    "            print(f\"Attempting to call model: {model}...\")\n",
    "            response = requests.post(\n",
    "                url=OPENROUTER_URL,\n",
    "                headers=OPENROUTER_HEADERS,\n",
    "                data=json.dumps({\"model\": model, \"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            print(f\"Successfully received response from {model}.\")\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to call {model}: {e}\")\n",
    "            print(\"Waiting 5 seconds before trying the next model...\")\n",
    "            time.sleep(5)\n",
    "    print(\"FATAL: All models failed.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082ead50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_collector_and_build_vectorstore(company):\n",
    "    \"\"\"\n",
    "    Step 1: Runs targeted searches, processes the content, and builds an in-memory\n",
    "    vector store (our RAG knowledge base).\n",
    "    \"\"\"\n",
    "    print(\"Step 1/3: Running targeted searches and building knowledge base...\")\n",
    "    gtm_queries = [\n",
    "        f'\"{company}\" recent major partnerships with enterprise companies',\n",
    "        f'\"{company}\" new CFO OR C-level executive hires',\n",
    "        f'\"{company}\" latest funding round and valuation',\n",
    "        f'\"{company}\" new product launches related to AI, orchestration, or enterprise',\n",
    "        f'\"{company}\" strategic shift OR focus on new industries',\n",
    "    ]\n",
    "    \n",
    "    # 1. Collect\n",
    "    all_results = []\n",
    "    for query in gtm_queries:\n",
    "        print(f\"  - Searching for: {query}\")\n",
    "        search_results = tavily_client.search(query=query, search_depth=\"advanced\", max_results=3)['results']\n",
    "        all_results.extend(search_results)\n",
    "    print(f\"Collected {len(all_results)} total search results.\")\n",
    "\n",
    "    # 2. Chunk\n",
    "    # Convert search results into LangChain Document objects\n",
    "    docs = [Document(page_content=res['content'], metadata={'source': res['url']}) for res in all_results]\n",
    "    \n",
    "    # Split the documents into smaller, more manageable chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunked_docs = text_splitter.split_documents(docs)\n",
    "    print(f\"Split content into {len(chunked_docs)} chunks.\")\n",
    "\n",
    "    # 3. Embed & Store\n",
    "    # This creates a searchable vector database in memory from the document chunks\n",
    "    vector_store = FAISS.from_documents(chunked_docs, embedding_model)\n",
    "    print(\"Knowledge base created successfully.\")\n",
    "    \n",
    "    return vector_store.as_retriever()\n",
    "\n",
    "\n",
    "def run_rag_analyst_node(retriever, company):\n",
    "    \"\"\"\n",
    "    Step 2: Asks key GTM questions one by one, retrieving relevant context\n",
    "    from the vector store for each question before generating an answer.\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 2/3: Answering key GTM questions using RAG...\")\n",
    "    \n",
    "    key_gtm_questions = [\n",
    "        f\"What is {company}'s most recently reported valuation and funding status?\",\n",
    "        f\"What major new enterprise partnerships or customers has {company} announced?\",\n",
    "        f\"Who are the recent, significant C-level executive hires at {company}?\",\n",
    "        f\"What major new products has {company} launched, especially regarding AI, Orchestration, or Enterprise features?\",\n",
    "        f\"What are the key strategic shifts or new industry focuses for {company}?\"\n",
    "    ]\n",
    "    \n",
    "    grounded_answers = []\n",
    "    for question in key_gtm_questions:\n",
    "        print(f\"  - Answering question: {question}\")\n",
    "        \n",
    "        # 1. Retrieve\n",
    "        relevant_docs = retriever.get_relevant_documents(question)\n",
    "        context_str = \"\\n\\n\".join([f\"Source: {doc.metadata['source']}\\nContent: {doc.page_content}\" for doc in relevant_docs])\n",
    "        \n",
    "        # 2. Generate\n",
    "        prompt = f\"\"\"\n",
    "        You are a factual analyst. Answer the user's question based *only* on the provided context.\n",
    "        List the key facts and cite the source URL for each fact.\n",
    "\n",
    "        CONTEXT:\n",
    "        ---\n",
    "        {context_str}\n",
    "        ---\n",
    "        \n",
    "        QUESTION: {question}\n",
    "\n",
    "        ANSWER:\n",
    "        \"\"\"\n",
    "        answer = call_openrouter_with_retry(prompt)\n",
    "        if answer:\n",
    "            grounded_answers.append({\"question\": question, \"answer\": answer})\n",
    "        time.sleep(3) # Small delay between questions\n",
    "        \n",
    "    print(\"All key questions answered.\")\n",
    "    return grounded_answers\n",
    "\n",
    "\n",
    "def run_editor_node(grounded_answers, company):\n",
    "    \"\"\"\n",
    "    Step 3: Assembles the high-quality, pre-answered questions into the final\n",
    "    polished GTM report.\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 3/3: Compiling the final GTM report...\")\n",
    "    answers_str = json.dumps(grounded_answers, indent=2)\n",
    "    prompt = f\"\"\"\n",
    "    You are a Senior Go-To-Market (GTM) Analyst. Your task is to synthesize the following pre-answered, fact-checked research notes into a final, polished intelligence briefing about \"{company}\".\n",
    "\n",
    "    **Instructions:**\n",
    "    1.  Review the questions and their detailed answers below.\n",
    "    2.  Do not add any new information. Your job is to structure and summarize.\n",
    "    3.  Create a comprehensive report in Markdown that includes:\n",
    "        a. A concise **Executive Summary**.\n",
    "        b. A **Key GTM Signals** section, summarizing the most important findings from the notes.\n",
    "        c. An **Actionable GTM Recommendations** section for a sales/marketing team based on the findings.\n",
    "        d. A **Reference List** containing all the unique source URLs mentioned in the answers.\n",
    "\n",
    "    **RESEARCH NOTES:**\n",
    "    ---\n",
    "    {answers_str}\n",
    "    ---\n",
    "    \n",
    "    **FINAL GTM INTELLIGENCE REPORT:**\n",
    "    \"\"\"\n",
    "    return call_openrouter_with_retry(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a8ef111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting GTM Intelligence Report Generation (RAG Version) ---\n",
      "Step 1/3: Running targeted searches and building knowledge base...\n",
      "  - Searching for: \"Stripe\" recent major partnerships with enterprise companies\n",
      "  - Searching for: \"Stripe\" new CFO OR C-level executive hires\n",
      "  - Searching for: \"Stripe\" latest funding round and valuation\n",
      "  - Searching for: \"Stripe\" new product launches related to AI, orchestration, or enterprise\n",
      "  - Searching for: \"Stripe\" strategic shift OR focus on new industries\n",
      "Collected 15 total search results.\n",
      "Split content into 23 chunks.\n",
      "Knowledge base created successfully.\n",
      "\n",
      "Step 2/3: Answering key GTM questions using RAG...\n",
      "  - Answering question: What is Stripe's most recently reported valuation and funding status?\n",
      "Attempting to call model: google/gemini-2.0-flash-exp:free...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/l_bc5j753tx9_bp8mg05l0x00000gn/T/ipykernel_51645/2488266599.py:60: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to call google/gemini-2.0-flash-exp:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: kwaipilot/kat-coder-pro:free...\n",
      "Failed to call kwaipilot/kat-coder-pro:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: openrouter/polaris-alpha...\n",
      "Successfully received response from openrouter/polaris-alpha.\n",
      "  - Answering question: What major new enterprise partnerships or customers has Stripe announced?\n",
      "Attempting to call model: google/gemini-2.0-flash-exp:free...\n",
      "Failed to call google/gemini-2.0-flash-exp:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: kwaipilot/kat-coder-pro:free...\n",
      "Failed to call kwaipilot/kat-coder-pro:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: openrouter/polaris-alpha...\n",
      "Successfully received response from openrouter/polaris-alpha.\n",
      "  - Answering question: Who are the recent, significant C-level executive hires at Stripe?\n",
      "Attempting to call model: google/gemini-2.0-flash-exp:free...\n",
      "Failed to call google/gemini-2.0-flash-exp:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: kwaipilot/kat-coder-pro:free...\n",
      "Failed to call kwaipilot/kat-coder-pro:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: openrouter/polaris-alpha...\n",
      "Successfully received response from openrouter/polaris-alpha.\n",
      "  - Answering question: What major new products has Stripe launched, especially regarding AI, Orchestration, or Enterprise features?\n",
      "Attempting to call model: google/gemini-2.0-flash-exp:free...\n",
      "Failed to call google/gemini-2.0-flash-exp:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: kwaipilot/kat-coder-pro:free...\n",
      "Failed to call kwaipilot/kat-coder-pro:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: openrouter/polaris-alpha...\n",
      "Successfully received response from openrouter/polaris-alpha.\n",
      "  - Answering question: What are the key strategic shifts or new industry focuses for Stripe?\n",
      "Attempting to call model: google/gemini-2.0-flash-exp:free...\n",
      "Failed to call google/gemini-2.0-flash-exp:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: kwaipilot/kat-coder-pro:free...\n",
      "Failed to call kwaipilot/kat-coder-pro:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: openrouter/polaris-alpha...\n",
      "Successfully received response from openrouter/polaris-alpha.\n",
      "All key questions answered.\n",
      "\n",
      "Step 3/3: Compiling the final GTM report...\n",
      "Attempting to call model: google/gemini-2.0-flash-exp:free...\n",
      "Failed to call google/gemini-2.0-flash-exp:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: kwaipilot/kat-coder-pro:free...\n",
      "Failed to call kwaipilot/kat-coder-pro:free: 429 Client Error: Too Many Requests for url: https://openrouter.ai/api/v1/chat/completions\n",
      "Waiting 5 seconds before trying the next model...\n",
      "Attempting to call model: openrouter/polaris-alpha...\n",
      "Successfully received response from openrouter/polaris-alpha.\n",
      "\n",
      "--- Report Generation Complete! ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Executive Summary\n",
       "\n",
       "Stripe is a $95B payments and financial infrastructure leader that is accelerating into an enterprise- and AI-first strategy. Recent funding ($6.5B Series I), high-profile enterprise wins (including Nvidia’s migration to Stripe Billing), extensive penetration of Fortune 100 and AI-native companies, and a broadened product stack (AI foundation model for payments, orchestration, stablecoin accounts, and the Agentic Commerce Protocol) reinforce Stripe’s position as a critical, scalable “financial OS” for modern businesses. These moves signal a platform built to lock in large customers, orchestrate complex multi-PSP environments, enable AI-driven and agent-led commerce, and prepare for public-market scale—making Stripe both a formidable competitor and a highly strategic ecosystem partner.\n",
       "\n",
       "---\n",
       "\n",
       "## Key GTM Signals\n",
       "\n",
       "### 1. Financial Strength & Strategic Maturity\n",
       "- **Valuation:** $95B.\n",
       "- **Funding:** $6.5B Series I led by top-tier investors (Thrive Capital, Andreessen Horowitz, Sequoia, General Catalyst).\n",
       "- **Signal:** Reinforces market confidence, supports long-term infrastructure investments, and suggests readiness for scaled enterprise commitments and potential IPO trajectory.\n",
       "\n",
       "### 2. Enterprise Penetration & Customer Proof\n",
       "- **Customer Base:**\n",
       "  - Serves **half of the Fortune 100**.\n",
       "  - Serves **78% of firms on the Forbes AI 50**, including OpenAI and Anthropic.\n",
       "  - Named enterprise customers include **NVIDIA, Pepsi, Rivian, Cloudflare, AMC Networks, Forbes**.\n",
       "- **Signal:** Strong validation as trusted infrastructure for global, high-volume, and AI-native enterprises; rising switching costs and reference power in complex, regulated, and high-growth environments.\n",
       "\n",
       "### 3. Strategic Enterprise & AI Partnerships\n",
       "- **Nvidia Partnership:** Deeper collaboration; Nvidia migrated its entire subscriber base to Stripe Billing.\n",
       "- **ACP with OpenAI & PwC:** Co-developed Agentic Commerce Protocol plus PwC partnership for enterprise adoption.\n",
       "- **Signal:** Stripe is positioning at the intersection of AI, agents, and payments—becoming core to how AI-native and enterprise ecosystems transact.\n",
       "\n",
       "### 4. Product & Platform Expansion\n",
       "\n",
       "**a. AI & Risk/Performance**\n",
       "- Launched an **AI foundation model for payments** to improve decisions, optimization, and fraud/risk outcomes.\n",
       "- Signal: Differentiates on intelligence and performance, not just basic processing.\n",
       "\n",
       "**b. Orchestration**\n",
       "- Introduced **Orchestration** to manage multiple payment providers via one Stripe dashboard, including for non-Stripe processing.\n",
       "- Signal: Stripe is embedding itself as the control layer in complex payment stacks—owning the customer relationship even in multi-PSP environments.\n",
       "\n",
       "**c. Stablecoin-Powered Accounts**\n",
       "- Launched **stablecoin-powered accounts**.\n",
       "- Signal: Aligns with next-gen payment rails and global, digital-native treasury needs—appealing to high-velocity and cross-border businesses.\n",
       "\n",
       "**d. Full-Stack Fintech Positioning**\n",
       "- Continues to expand beyond payments into a **comprehensive fintech stack**: fraud prevention, analytics, lending, Billing, Issuing, Treasury, and more.\n",
       "- Signal: Strategy to increase product density and stickiness; positions Stripe as a one-stop financial infrastructure provider.\n",
       "\n",
       "### 5. Leadership & IPO Readiness\n",
       "- **New CFO:** Steffan Tomlinson (ex-Confluent, experience at Google and other large tech firms).\n",
       "- **Signal:** Explicit move toward operational rigor, scalability, and capital markets readiness—consistent with IPO expectations and enterprise-grade governance.\n",
       "\n",
       "### 6. Core Strategic Positioning\n",
       "- **“Financial plumbing” for platforms:** Deep embedding into ecosystems (e.g., platforms like Shopify, Lyft) where Stripe grows as they grow.\n",
       "- **Enterprise focus:** Increasing emphasis on large, complex customers and AI-first companies.\n",
       "- **Signal:** Stripe is solidifying its role as indispensable infrastructure for both platforms and enterprises, raising barriers to entry for competitors.\n",
       "\n",
       "---\n",
       "\n",
       "## Actionable GTM Recommendations\n",
       "\n",
       "### 1. Target Segments & Positioning\n",
       "\n",
       "1. **Focus on enterprise and high-growth scale-ups**\n",
       "   - Prioritize accounts that:\n",
       "     - Operate globally and need multi-PSP, multi-currency, or complex billing.\n",
       "     - Are AI-native, subscription-based, marketplace, or platform businesses.\n",
       "   - Position against Stripe by emphasizing:\n",
       "     - Differentiated capabilities where relevant (e.g., vertical specialization, bespoke compliance, local payment methods, service quality, or cost transparency).\n",
       "     - Interoperability and reduced lock-in versus Stripe’s increasingly integrated stack.\n",
       "\n",
       "2. **Lean into AI-native and agentic commerce narratives**\n",
       "   - For AI, SaaS, and platform prospects:\n",
       "     - Frame offerings as complementary or competitive to Stripe’s AI foundation model and ACP approach.\n",
       "     - Highlight ability to integrate with AI agents, automate financial workflows, or enhance risk/authorization performance.\n",
       "\n",
       "### 2. Competitive Displacement & Coexistence Plays\n",
       "\n",
       "1. **Exploit Orchestration as an entry point**\n",
       "   - Where Stripe Orchestration is present or under evaluation:\n",
       "     - Offer value as a specialized provider inside multi-PSP architectures (e.g., better performance in certain geos, payment methods, or risk profiles).\n",
       "     - Provide migration and optimization services that work alongside or in place of Stripe, focusing on reducing dependency.\n",
       "\n",
       "2. **Target pain from one-stop-stack lock-in**\n",
       "   - Speak to enterprises wary of:\n",
       "     - Vendor concentration risk.\n",
       "     - Limited customization or commercial leverage.\n",
       "   - Provide GTM content and sales plays around:\n",
       "     - Multi-provider resilience.\n",
       "     - Transparent economics.\n",
       "     - Regulatory and data localization flexibility versus a single global stack.\n",
       "\n",
       "### 3. Enterprise Sales Motions\n",
       "\n",
       "1. **Use Stripe’s references as proof of category maturity**\n",
       "   - Acknowledge Stripe’s role to validate the category, then:\n",
       "     - Position your solution as better suited for specific needs (regulated industries, niche markets, on-prem/hybrid, sovereignty, deep integration).\n",
       "   - Build case studies that mirror Stripe-style logos (large platforms, AI leaders) to de-risk choice.\n",
       "\n",
       "2. **Engage finance and ops stakeholders early**\n",
       "   - Stripe’s CFO-level maturity and IPO trajectory imply buyers expect:\n",
       "     - Robust reporting, compliance, auditability, cost control.\n",
       "   - Arm sales teams with:\n",
       "     - Detailed TCO models.\n",
       "     - ROI calculators tied to approval uplift, churn reduction, working capital improvements.\n",
       "\n",
       "### 4. Product Marketing & Messaging\n",
       "\n",
       "1. **Theme: “Intelligent, open, resilient payments infrastructure”**\n",
       "   - Emphasize:\n",
       "     - Intelligence (risk/AI capabilities).\n",
       "     - Openness (no lock-in, easy switching, ecosystem integrability).\n",
       "     - Resilience (multi-rail, multi-PSP, regional redundancy).\n",
       "\n",
       "2. **Content Strategy**\n",
       "   - Publish:\n",
       "     - Comparisons that articulate when enterprises should consider multi-PSP or alternatives to a monolithic provider.\n",
       "     - POVs on AI in payments, stablecoins, and agentic commerce that reference Stripe’s moves as validation without adding new facts.\n",
       "\n",
       "### 5. Partner & Ecosystem Strategy\n",
       "\n",
       "1. **Collaborate with consultants & SIs**\n",
       "   - Mirror Stripe’s collaboration with PwC:\n",
       "     - Enable consultancies and SIs with playbooks for designing multi-PSP or specialized stacks including (or competing with) Stripe.\n",
       "   - Train partners to:\n",
       "     - Identify when Stripe’s integrated approach may not be optimal and propose complementary/alternative architectures.\n",
       "\n",
       "---\n",
       "\n",
       "## Reference List\n",
       "\n",
       "- https://salestools.io/report/stripe-6-5b-series-i-july-2025  \n",
       "- https://www.linkedin.com/posts/maryannazevedo_stripe-unveils-ai-foundation-model-for-payments-activity-7325996173222105088-Jr6z  \n",
       "- https://rfadvisorslimited.com/stripe-unveils-ai-foundation-model-for-payments-reveals-deeper-partnership-with-nvidia-techcrunch/  \n",
       "- https://fintechmagazine.com/news/payments-giant-stripe-nabs-10th-in-top-100-fintech-companies  \n",
       "- https://stripe.com/newsroom/news/tour-newyork-2024  \n",
       "- https://www.paymentsdive.com/news/former-google-cloud-cfo-heads-to-stripe/689910/  \n",
       "- https://dataconomy.com/2025/05/08/stripe-dives-into-stablecoins-rolls-out-major-ai-tools/  \n",
       "- https://www.pwc.com/us/en/about-us/newsroom/press-releases/stripe-collaboration-next-era-agentic-commerce.html  \n",
       "- https://strategybreakdowns.com/p/stripe-platform-strategy  \n",
       "- https://www.forbes.com/sites/danielwebber/2025/09/23/stripes-ipo-potential-is-stronger-than-ever/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Define the Research Target ---\n",
    "COMPANY_NAME = \"Stripe\"\n",
    "\n",
    "# --- Run the RAG-Powered Workflow ---\n",
    "print(\"--- Starting GTM Intelligence Report Generation (RAG Version) ---\")\n",
    "\n",
    "# Step 1: Collect data and build the searchable knowledge base\n",
    "retriever = run_collector_and_build_vectorstore(COMPANY_NAME)\n",
    "\n",
    "# Step 2: Use RAG to answer key GTM questions factually\n",
    "if retriever:\n",
    "    grounded_answers = run_rag_analyst_node(retriever, COMPANY_NAME)\n",
    "else:\n",
    "    grounded_answers = []\n",
    "\n",
    "# Step 3: Compile the final report from the high-quality answers\n",
    "if grounded_answers:\n",
    "    final_report = run_editor_node(grounded_answers, COMPANY_NAME)\n",
    "    print(\"\\n--- Report Generation Complete! ---\")\n",
    "else:\n",
    "    final_report = \"Could not generate a report as no grounded answers were available.\"\n",
    "\n",
    "# --- Display the Final GTM Intelligence Report ---\n",
    "display(Markdown(final_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d432f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the GTM report to: gtm_intelligence_report_stripe.md\n"
     ]
    }
   ],
   "source": [
    "# --- Save the final report to a Markdown file ---\n",
    "\n",
    "# Define the filename\n",
    "output_filename = \"gtm_intelligence_report_stripe.md\"\n",
    "\n",
    "try:\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(final_report)\n",
    "    print(f\"Successfully saved the GTM report to: {output_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
